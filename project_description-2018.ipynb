{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSFB Course Project: Predicting IPO Share Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://img.etimg.com/thumb/height-480,width-640,msid-64038320,imgsize-108012/stock-market2-getty-images.jpg)\n",
    "\n",
    "image source : https://img.etimg.com/thumb/height-480,width-640,msid-64038320,imgsize-108012/stock-market2-getty-images.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Initial Public Offering (IPO) is the process by which a private company becomes publicly traded on a stock exchange. The IPO company offers its shares to public investors in exchange of capital for sustaining expansion and growth. For this reason, IPOs are often issued by small or young companies, but they can also be done by large  companies looking to become publicly traded. During an IPO, the company obtains the assistance of an investment bank (underwriter), which helps determine the type, amount and price of the shares being offered. Decisions about the offering price are particularly important to avoid incurring excessive costs and maximize the capital received in the IPO. However at the end of the first trading day, price of each share can change due to market dynamics, which can lead to a price higher or lower than the offering one.\n",
    "\n",
    "During an Initial Public Offering (IPO), the firm’s management have to disclose all relevant information about their business in a filing with the government called the \"IPO Prospectus.\" Although there might be concerns about the public disclosure of sensitive information in the Prospectus that can help competitors, firms are encouraged to be as transparent as possible in order to avoid future litigation (lawsuits). A key textual field from the prospectus is:\n",
    "\n",
    "__Risk_Factors__: Firms have to disclose all relevant information about internal or external risk factors that might affect future business performances. This information is contained in the “Risk Factors” section of the IPO prospectus. \n",
    "\n",
    "The key pricing variables are:\n",
    "\n",
    "__Offering_Price__: the price at which a company sells its shares to investors.\n",
    "\n",
    "__Num_Shares__: the total number of outstanding shares.\n",
    "\n",
    "__Closing_Price__: (at the end of the first day of training) price at which shares trade in the open market, measured at the end of the first day of trading.\n",
    "\n",
    "In this project you are provided with IPO data of different firms that are collected from different sources. You can find the dataset under project directory in the course git repository under the name of *ipo.xlsx*. The description of other variables can be found in *variable_description.xlsx*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd     \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re as re\n",
    "import nltk\n",
    "import datetime as dt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from model_helpers import *\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_functions import *\n",
    "from model_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataset\n",
    "DATA_FOLDER = 'data'\n",
    "\n",
    "#Cost TIME\n",
    "ipo = pd.read_csv(DATA_FOLDER+'/data_non_textual_clean.csv')\n",
    "ipo_predict = pd.read_csv(DATA_FOLDER+'/data_non_textual_clean_predict.csv')\n",
    "\n",
    "ipo_text =  pd.read_csv(DATA_FOLDER+'/data_textual_clean.csv')\n",
    "#ipo_text_predict = pd.read_csv(DATA_FOLDER+'/data_textual_clean_predict.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 5742)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(474, 5742)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipo_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipo.columns[ipo.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " _________________________________________________________ \n",
    "# Part 1\n",
    "\n",
    "Predict whether the closing price is higher than the offering price using non-text fields. By non-text fields, we mean all fields except the 'Risk_Factors'. If the price goes up from opening to closing, assign a value of 1 to a new target variable called __Price_Increase__, otherwise assign 0.\n",
    "\n",
    "    f(non-text-fields) -> Probability of being in class 1 \n",
    "\n",
    "For the evaluation metric, report the area under the curve (AUC) and plot an ROC graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipo_models = ipo.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipo_models['Target'] = ipo_models.Closing_Price >= ipo_models.Offering_Price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ipo_models.Closing_Price == ipo_models.Offering_Price )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ipo_models['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipo_models.Target = ipo_models.Target.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = ipo_models['Target'].value_counts()\n",
    "\n",
    "sns.set()\n",
    "\n",
    "ones = counts[1]/len(counts) * 100\n",
    "zeros = counts[0]/len(counts) * 100\n",
    "labels = 'Price increased', 'Price decreased'\n",
    "plt.pie( [ones, zeros], labels=labels, autopct='%1.2f%%', startangle=360)\n",
    "plt.title('Distribution of target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ipo_models['Target'] \n",
    "features = ipo_models.drop(['Risk_Factors','Target','Closing_Price'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data is umbalanced as suggested by the exercise we will use roc auc as our metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate Train, Validate & Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate target and features into test and training and validation sets\n",
    "seed = 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.2, random_state = seed)\n",
    "X_train_train, X_train_val, y_train_train, y_train_val = train_test_split(X_train, y_train, test_size = 0.25, random_state = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Plot_functions import *\n",
    "bbaseline_clf = DummyClassifier(strategy='stratified', random_state = seed)\n",
    "\n",
    "# Fit the dummy classifier \n",
    "bbaseline_clf.fit(X_train,y_train)\n",
    "\n",
    "# Predict target probabilities of belonging to positive class\n",
    "y_pred = bbaseline_clf.predict_proba(X_test)\n",
    "\n",
    "# Compute area under the curve score\n",
    "print('auc',roc_auc_score(y_test, y_pred[:,1]))\n",
    "\n",
    "plot_roc_curve('Dummy',y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see it's like a random classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_clf = LogisticRegression() \n",
    "baseline_clf.fit(X_train,y_train)\n",
    "y_pred = baseline_clf.predict_proba(X_test)\n",
    "print('Score ',roc_auc_score(y_test, y_pred[:,1]))\n",
    "plot_roc_curve('Logistic Regression',y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##0.7705708446596162"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression tuning c penalty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Standardize features and classifier in a single pipeline\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('lr_clf', LogisticRegression()))\n",
    "pipeline = Pipeline(estimators)\n",
    "pipeline.set_params(lr_clf__penalty='l1')\n",
    "\n",
    "# Finding best value of C using validation set\n",
    "scores = []\n",
    "Cs = []\n",
    "for C in np.logspace(-4, 5, 10):\n",
    "    pipeline.set_params(lr_clf__C=C) \n",
    "    pipeline.fit(X_train,y_train)\n",
    "    y_train_pred = pipeline.predict_proba(X_test)\n",
    "    scores.append(roc_auc_score(y_test, y_train_pred[:,1]))\n",
    "    Cs.append(C)\n",
    "\n",
    "best_C = Cs[scores.index(max(scores))]\n",
    "print ('best C = %d with auc score = %2.4f' %(best_C, max(scores)))\n",
    "\n",
    "# Performance of the tuned model on test set\n",
    "pipeline.set_params(lr_clf__C=best_C)\n",
    "pipeline.fit(X_train,y_train)\n",
    "y_pred_lr = pipeline.predict_proba(X_test)\n",
    "score = roc_auc_score(y_test, y_pred_lr[:,1])\n",
    "print ('lr classifer auc with l1 regularization = %2.4f' %score)\n",
    "plot_roc_curve('l1 regularization',y_pred_lr,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN tuning N neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features and classifier in a single pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('knn_clf', KNeighborsClassifier()))\n",
    "pipeline = Pipeline(estimators)\n",
    "\n",
    "# Finding best value of K using validation set\n",
    "scores = []\n",
    "Ks = []\n",
    "for K in [int(i) for i in np.linspace(5, 95, 10)]:\n",
    "    pipeline.set_params(knn_clf__n_neighbors = K) \n",
    "    pipeline.fit(X_train_train,y_train_train)\n",
    "    y_train_pred = pipeline.predict_proba(X_train_val)\n",
    "    scores.append(roc_auc_score(y_train_val, y_train_pred[:,1]))\n",
    "    Ks.append(K)\n",
    "\n",
    "best_K = Ks[scores.index(max(scores))]\n",
    "print ('best K = %d with auc score = %2.4f' %(best_K, max(scores)))\n",
    "\n",
    "# Performance of the tuned model on test set\n",
    "pipeline.set_params(knn_clf__n_neighbors = best_K)\n",
    "pipeline.fit(X_train,y_train)\n",
    "y_pred_knn = pipeline.predict_proba(X_test)\n",
    "score = roc_auc_score(y_test, y_pred_knn[:,1])\n",
    "print ('knn classifer auc = %2.4f' %score)\n",
    "plot_roc_curve('KNN',y_pred_knn,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define a random classifier pipeline\n",
    "estimators = []\n",
    "estimators.append(('rf_clf', RandomForestClassifier()))\n",
    "pipeline = Pipeline(estimators)\n",
    "pipeline.set_params(rf_clf__random_state = seed)\n",
    "    \n",
    "# Finding best value of n_estimators using validation set\n",
    "scores = []\n",
    "NSs = []\n",
    "for NS in [int(i) for i in np.linspace(10, 100, 10)]:\n",
    "    pipeline.set_params(rf_clf__n_estimators = NS) \n",
    "    pipeline.fit(X_train_train,y_train_train)\n",
    "    y_train_pred = pipeline.predict_proba(X_train_val)\n",
    "    scores.append(roc_auc_score(y_train_val, y_train_pred[:,1]))\n",
    "    NSs.append(NS)\n",
    "\n",
    "best_NS = NSs[scores.index(max(scores))]\n",
    "print ('best NS = %d with auc score = %2.4f' %(best_NS, max(scores)))\n",
    "\n",
    "# Performance of the tuned model on test set\n",
    "pipeline.set_params(rf_clf__n_estimators = best_NS)\n",
    "pipeline.fit(X_train,y_train)\n",
    "y_pred_rf = pipeline.predict_proba(X_test)\n",
    "score = roc_auc_score(y_test, y_pred_rf[:,1])\n",
    "print ('rf classifer auc = %2.4f' %score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve('KNN',y_pred_rf,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Gradient Boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Define a random classifier pipeline\n",
    "estimators = []\n",
    "estimators.append(('gb_clf', GradientBoostingClassifier()))\n",
    "pipeline = Pipeline(estimators)\n",
    "pipeline.set_params(gb_clf__random_state = seed)\n",
    "    \n",
    "# Finding best value of n_estimators using validation set\n",
    "scores = []\n",
    "NSs = []\n",
    "for NS in [int(i) for i in np.linspace(10, 100, 10)]:\n",
    "    pipeline.set_params(gb_clf__n_estimators = NS) \n",
    "    pipeline.fit(X_train_train,y_train_train)\n",
    "    y_train_pred = pipeline.predict_proba(X_train_val)\n",
    "    scores.append(roc_auc_score(y_train_val, y_train_pred[:,1]))\n",
    "    NSs.append(NS)\n",
    "\n",
    "best_NS = NSs[scores.index(max(scores))]\n",
    "print ('best NS = %d with auc score = %2.4f' %(best_NS, max(scores)))\n",
    "\n",
    "# Performance of the tuned model on test set\n",
    "pipeline.set_params(gb_clf__n_estimators = best_NS)\n",
    "pipeline.fit(X_train,y_train)\n",
    "y_pred_gb = pipeline.predict_proba(X_test)\n",
    "score = roc_auc_score(y_test, y_pred_gb[:,1])\n",
    "plot_roc_curve('GradientBoostingClassifier',y_pred_gb,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance(pipeline,features,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "Predict whether the closing price is higher than the offering price using __only__ textual field 'Risk_Factors'. If the price goes up from opening to closing, assign a value of 1 to a new target variable called __Price_Increase__, otherwise assign 0.\n",
    "\n",
    "    f(text-fields) -> Probability of being in class 1 \n",
    "\n",
    "For the evaluation metric, report the area under the curve (AUC) and plot an ROC graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get textual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy dataframe\n",
    "text_features = ipo_text.copy()\n",
    "text_target = target[0:len(text_features)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "seed = 0\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('rf_clf', RandomForestClassifier()))\n",
    "rf_pipe = Pipeline(estimators)\n",
    "rf_pipe.set_params(rf_clf__random_state = seed)\n",
    "\n",
    "# Fixed parameters\n",
    "score = 'accuracy'\n",
    "\n",
    "# Setup possible values of parameters to optimize over\n",
    "p_grid = {\"rf_clf__n_estimators\": [int(i) for i in np.linspace(10.0, 50.0, 5)]}\n",
    "\n",
    "nested_cv(X = text_features, y = text_target, est_pipe = rf_pipe, p_grid = p_grid, p_score = score, n_cores = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Regroupe to 50 Fields \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "\n",
    "principalComponents = pca.fit_transform(text_features)\n",
    "principalComponents = pd.DataFrame(principalComponents)\n",
    "\n",
    "\n",
    "\n",
    "#Update the name of the columns\n",
    "# get length of df's columns\n",
    "num_cols = 100\n",
    "# generate range of ints for suffixes\n",
    "rng = range(0,num_cols)\n",
    "\n",
    "new_cols = [ 'risk_'+str(i) for i in rng]\n",
    "\n",
    "# ensure the length of the new columns list is equal to the length of df's columns\n",
    "principalComponents.columns = new_cols[:num_cols]\n",
    "\n",
    "principalComponents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('rf_clf', RandomForestClassifier()))\n",
    "rf_pipe = Pipeline(estimators)\n",
    "rf_pipe.set_params(rf_clf__random_state = seed)\n",
    "\n",
    "# Fixed parameters\n",
    "score = 'accuracy'\n",
    "\n",
    "# Setup possible values of parameters to optimize over\n",
    "p_grid = {\"rf_clf__n_estimators\": [int(i) for i in [10, 20, 50, 100]]}\n",
    "\n",
    "nested_cv(X = principalComponents, y = text_target, est_pipe = rf_pipe, p_grid = p_grid, p_score = score, n_cores = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Word Vectors : Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "\n",
    "def review_to_wordlist( review ):\n",
    "    \n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "   \n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    \n",
    "    words = review_text.lower().split()\n",
    "    \n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    words = [w for w in words if not w in stops]\n",
    "    \n",
    "    stemmer = SnowballStemmer('english')\n",
    "    words = [stemmer.stem(w) for w in words]\n",
    "    \n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to split a review into parsed sentences, where each sentence is a word list\n",
    "\n",
    "def review_to_sentences( review, tokenizer ):\n",
    "    \n",
    "    raw_sentences = tokenizer.tokenize(review.strip())  \n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:      \n",
    "        if len(raw_sentence) > 0:           \n",
    "            sentences.append( review_to_wordlist( raw_sentence ))\n",
    "   \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentences = []\n",
    "risks = ipo['Risk_Factors']\n",
    "for risk in risks:\n",
    "    sentences += review_to_sentences(risk, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train word vectors\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set values for various parameters\n",
    "num_features = 300    # word vector dimensionality                      \n",
    "min_word_count = 40   # minimum word count                        \n",
    "num_workers = 16      # number of threads to run in parallel\n",
    "context = 10          # context window size                                                                                    \n",
    "\n",
    "# Initialize and train the model \n",
    "from gensim.models import word2vec\n",
    "print ('Training model...')\n",
    "w2v_model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context)\n",
    "print ('Done !')\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient\n",
    "w2v_model.init_sims(replace=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to average all of the word vectors in a given paragraph\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    \n",
    "    # Pre-initialize an empty numpy array (for speed)\n",
    "    featureVec = np.zeros((num_features,), dtype='float32')\n",
    "    nwords = 0.\n",
    "     \n",
    "    # Index2word is a list that contains the names of the words in \n",
    "    # the model's vocabulary. convert it to a set, for speed \n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    # Loop over each word in the review and, if it is in the model's\n",
    "    # vocaublary, add its feature vector to the total\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    \n",
    "    # Divide the result by the number of words to get the average\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Given a set of reviews (each one a list of words), calculate \n",
    "# the average feature vector for each one and return a 2D numpy array\n",
    "\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    \n",
    "    # Initialize a counter\n",
    "    counter = 0\n",
    "    \n",
    "    # Preallocate a 2D numpy array, for speed\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype='float32')\n",
    "     \n",
    "    # Loop through the reviews\n",
    "    for review in reviews:\n",
    "       \n",
    "       # Print a status message every 1000th review\n",
    "       if counter%1000 == 0:\n",
    "           print ('Review %d of %d' % (counter, len(reviews)))\n",
    "       \n",
    "       # Call the function (defined above) that makes average feature vectors\n",
    "       reviewFeatureVecs[counter] = makeFeatureVec(review, model, num_features)\n",
    "       \n",
    "       # Increment the counter\n",
    "       counter = counter + 1\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average feature vectors for review data,\n",
    "# using the functions we defined above.\n",
    "\n",
    "clean_data_reviews = []\n",
    "for review in ipo['Risk_Factors']:\n",
    "    clean_data_reviews.append( review_to_wordlist( review ))\n",
    "\n",
    "w2v_features = getAvgFeatureVecs( clean_data_reviews, w2v_model, num_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%time\n",
    "warnings.filterwarnings('ignore')\n",
    "seed = 0\n",
    "\n",
    "# Define pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('rf_clf', RandomForestClassifier()))\n",
    "rf_pipe = Pipeline(estimators)\n",
    "rf_pipe.set_params(rf_clf__random_state = seed)\n",
    "\n",
    "# Fixed parameters\n",
    "score = 'accuracy'\n",
    "\n",
    "# Setup possible values of parameters to optimize over\n",
    "p_grid = {\"rf_clf__n_estimators\": [int(i) for i in np.linspace(10.0, 50.0, 5)]}\n",
    "\n",
    "nested_cv(X = w2v_features, y = target, est_pipe = rf_pipe, p_grid = p_grid, p_score = score, n_cores = -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using Random Forest with Average Word2Vec Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "warnings.filterwarnings('ignore')\n",
    "seed = 0\n",
    "\n",
    "# Define pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('rf_clf', RandomForestClassifier()))\n",
    "rf_pipe = Pipeline(estimators)\n",
    "rf_pipe.set_params(rf_clf__random_state = seed)\n",
    "\n",
    "# Fixed parameters\n",
    "score = 'accuracy'\n",
    "\n",
    "# Setup possible values of parameters to optimize over\n",
    "p_grid = {\"rf_clf__n_estimators\": [int(i) for i in np.linspace(10.0, 50.0, 5)]}\n",
    "\n",
    "nested_cv(X = w2v_features, y = target, est_pipe = rf_pipe, p_grid = p_grid, p_score = score, n_cores = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paragraph vectors : Doc2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doc2Vec needs each review to be tagged with some sort of ids\n",
    "# Here we tag each review with the 'id' field\n",
    "\n",
    "import gensim\n",
    "\n",
    "tagged_clean_data_reviews = []\n",
    "for uid, review in zip(data['id'], clean_data_reviews):\n",
    "    tagged_clean_data_reviews.append(gensim.models.doc2vec.TaggedDocument(words=review, tags=['%s' % uid[1:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "\n",
    "Predict whether the closing price is higher than the offering price using __all__ fields. If the price goes up from opening to closing, assign a value of 1 to a new target variable called __Price_Increase__, otherwise assign 0.\n",
    "\n",
    "    f(all-fields) -> Probability of being in class 1 \n",
    "    \n",
    "For the evaluation metric, report the area under the curve (AUC) and plot an ROC graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge all features and get train, validate and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = pd.concat([text_features, features], axis=1)\n",
    "\n",
    "# Separate target and features into test and training and validation sets\n",
    "seed = 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_features, target, test_size = 0.2, random_state = seed)\n",
    "X_train_train, X_train_val, y_train_train, y_train_val = train_test_split(X_train, y_train, test_size = 0.25, random_state = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipeline\n",
    "estimators = []\n",
    "estimators.append(('xgb_clf', XGBClassifier()))\n",
    "xgb_pipe = Pipeline(estimators)\n",
    "xgb_pipe.set_params(xgb_clf__n_jobs = -1)\n",
    "xgb_pipe.set_params(xgb_clf__random_state = seed)\n",
    "\n",
    "# Fixed parameters\n",
    "score = 'roc_auc'\n",
    "\n",
    "# Finding best value of n_estimators using validation set\n",
    "scores = []\n",
    "NSs = []\n",
    "for NS in [int(i) for i in np.linspace(10, 100, 10)]:\n",
    "    xgb_pipe.set_params(xgb_clf__n_estimators = NS) \n",
    "    xgb_pipe.fit(X_train_train,y_train_train)\n",
    "    y_train_pred = xgb_pipe.predict_proba(X_train_val)\n",
    "    scores.append(roc_auc_score(y_train_val, y_train_pred[:,1]))\n",
    "    NSs.append(NS)\n",
    "\n",
    "best_NS = NSs[scores.index(max(scores))]\n",
    "print ('best NS = %d with auc score = %2.4f' %(best_NS, max(scores)))\n",
    "\n",
    "# Performance of the tuned model on test set\n",
    "xgb_pipe.set_params(xgb_clf__n_estimators = best_NS)\n",
    "xgb_pipe.fit(X_train,y_train)\n",
    "y_pred_gb = xgb_pipe.predict_proba(X_test)\n",
    "score = roc_auc_score(y_test, y_pred_gb[:,1])\n",
    "plot_roc_curve('GradientBoostingClassifier',y_pred_gb,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "[joblib] Attempting to do parallel computing without protecting your import on a system that does not support forking. To use parallel-computing in a script, you must protect your main loop using \"if __name__ == '__main__'\". Please see the joblib documentation on Parallel for more information",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-56f093665d02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# Train and evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mnested_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mest_pipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_pipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/dsfb-fall-2018-team-11/model_helpers.py\u001b[0m in \u001b[0;36mnested_cv\u001b[0;34m(X, y, est_pipe, p_grid, p_score, n_splits_inner, n_splits_outer, n_cores, seed)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Nested CV with parameter optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mnested_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mouter_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_cores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Average score: %0.4f (+/- %0.4f)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnested_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.96\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aborting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m             \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_effective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_initialize_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n\u001b[0;32m--> 547\u001b[0;31m                                              **self._backend_args)\n\u001b[0m\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_timeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m                 warnings.warn(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mconfigure\u001b[0;34m(self, n_jobs, parallel, **backend_args)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malready_forked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             raise ImportError(\n\u001b[0;32m--> 305\u001b[0;31m                 \u001b[0;34m'[joblib] Attempting to do parallel computing '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m                 \u001b[0;34m'without protecting your import on a system that does '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0;34m'not support forking. To use parallel-computing in a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: [joblib] Attempting to do parallel computing without protecting your import on a system that does not support forking. To use parallel-computing in a script, you must protect your main loop using \"if __name__ == '__main__'\". Please see the joblib documentation on Parallel for more information"
     ]
    }
   ],
   "source": [
    "# Fix random seed for reproducibility\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Build neural network model\n",
    "def create_model(nbr_l1, nbr_l2, nbr_l3):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nbr_l1, input_dim=all_features.shape[1], activation='relu'))\n",
    "    model.add(Dense(nbr_l2, activation='relu'))\n",
    "    model.add(Dense(nbr_l3, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    " \n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "nn_score = []\n",
    "for i in range(3,7,1):\n",
    "    nbr_l1 = pow(2,(i+2))\n",
    "    nbr_l2 = pow(2,(i+1))\n",
    "    nbr_l3 = pow(2,(i))\n",
    "    model = create_model(nbr_l1, nbr_l2, nbr_l3)\n",
    "    \n",
    "    # Create pipeline using keras wrapper for sklearn\n",
    "    estimators = []\n",
    "    estimators.append(('standardize', StandardScaler()))\n",
    "    estimators.append(('nn_clf', KerasClassifier(build_fn=create_model)))\n",
    "    nn_pipe = Pipeline(estimators)\n",
    "    nn_pipe.set_params(nn_clf__epochs = 2)\n",
    "    nn_pipe.set_params(nn_clf__batch_size = 10)\n",
    "    nn_pipe.set_params(nn_clf__verbose = 2)\n",
    "\n",
    "    # Setup possible values of parameters to optimize over\n",
    "    p_grid = {}\n",
    "\n",
    "    # Fixed parameters\n",
    "    score = 'roc_auc'\n",
    "\n",
    "    # Train and evaluate model\n",
    "    #Train the pipe\n",
    "    nn_pipe.fit(X_train_train, y_train_train )\n",
    "    # Get predicted values\n",
    "    nn1_predict = nn_pipe.predict_proba(X_train_val)\n",
    "    score = roc_auc_score(y_train_val, nn_predict[:,1])\n",
    "    print(\"\")\n",
    "    nn_score.append(score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4\n",
    "  \n",
    "Predict the share price at the end of the day using __all__ fields.\n",
    "\n",
    "    f(all-fields) ->  Share price at the end of the first day of trading\n",
    "    \n",
    "For the evaluation metric, report statisitcs for R-squared, Residual Mean Squared Error, Mean Absolute Error, and Median Absolute Error; however, be sure to tune and hypertune your models using R-Squared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "As mentioned earlier, you can find the dataset under project directory in the course git repository under the name of *ipo.xlsx*. The description of each variable can also be found in *variable_description.xlsx*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "We expect your solution for each step to contain the following:\n",
    "\n",
    "* data preprocessing and feature extraction (can be shared across different steps)\n",
    "* feature reduction\n",
    "* train, tune and test different predictive models\n",
    "* model comparison and arguing about the best model (don't forget mentioning a baseline model)\n",
    "* predict the labels of the to_predict dataset using your final model\n",
    "* discussion on possible additional tasks that can be done to boost the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverables\n",
    "\n",
    "* Predict values from your *best* predictive model for the target variable in Parts 1 to 4 above, and insert those values into the file __*ipo_to_predict.xlsx*__ The fields to be completed by you are: __Price_Change_Non_Textual__ (Part 1), __Price_Change_Textual__ (Part 2), __Price_Change_All__ (Part 3), and __Price_All__ (Part 4).  \n",
    "  \n",
    "  \n",
    "* Deliver a Jupyter notebook with an explanation of your methods, codes and results. Don't forget to divide your notebook into different parts, which clearly shows your solution to the common pre-processing as well as different steps separately. \n",
    "    \n",
    "    \n",
    "\n",
    "* Submit your final notebook and files into the git repository of the team (we will create that git repo for you).\n",
    "\n",
    "\n",
    "* Present your results in the final session of the course. Communicate them in a clear and concise manner. The goal is to learn how to present your results to stakeholders at the right level of detail. **We will discuss this more in classe**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips\n",
    "\n",
    "* Take some time at the start of the project to educate yourslef about the IPO process. We privde you wiht two main texts in the class repository under *resources* folder. Understanding how variables relate to the target outcomes will help you to construct new measures from the tabularized data and/or selecting or eliminating features that relate to the target variable.  \n",
    "\n",
    "\n",
    "* Present your results as a story - this is very important!   \n",
    "  \n",
    "\n",
    "* Document all of your assumptions (e.g. evaluation metric, hyper-parameter values, ...).  \n",
    "\n",
    "\n",
    "* Make sure your code will run and results are reproducible (fix random seeds, etc.).  \n",
    "\n",
    "\n",
    "*  Comment your blocks of code (and lines of code if needed) and anything in your story/logic that might not be obvious by looking at your code.    \n",
    "\n",
    "\n",
    "* To speed up experimentation, you might use a small sample of the original dataset to do your initial coding. Also try to use all possible cores for computation, by setting the option of n_jobs = -1, when needed. \n",
    "\n",
    "\n",
    "* Try to be creative to improve your predictions, but don't forget that it is also important to explain your line of thinking/reasoning.\n",
    "\n",
    "\n",
    "* Your final grade is based on the whole process of doing the project and not just based on your results on the unseen data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading\n",
    "\n",
    "Grading of the project (apart from presentation), is based on the following components:\n",
    "    \n",
    "    20 %  Documentation and organization of your notebook\n",
    "    15 %  Quality and commenting of code\n",
    "    10 %  Pre-processing\n",
    "    15 %  Part 1\n",
    "    15 %  Part 2\n",
    "    10 %  Part 3\n",
    "    15 %  Part 4\n",
    "    \n",
    "     5%   Bonus Contest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Contest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an optional bonus contest at the end of the project, we will award an extra 5% of the total project grade to the team that comes up with the \"best\" strategy for investing into IPOs based on your estimated model(s). Specifically, assume you have USD 1,000,000 to invest into the IPO stocks that appear in the \"unseen\" file __*ipo_to_predict.xlsx*__. In the column \"Your_Bet\", allocate some portion of that USD 1,000,000 to each of the stocks listed in the unseen file. The total allocation must sum to $1,000,000. The top team making the most money (once outcomes are revealed at time of grading) will earn the 5% bonus. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
